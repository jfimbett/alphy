I am developing a Next.js application for private equity funds to be able to upload documents and have them
analyzed using Large Language Models. The application allows for signup/login, and some persistence of user data.
The application is built mostly using typescript, and uses a local postgres database for storing data, as well as some local storage 
in the folder of the application for large data.A normal workflow for a user is to upload a folder with documents, 
select the documents that the users wants analyzed, then the LLM first summarizes the document, then it identifies key variablesto extract, then
it extracts that information, and finally there is a consolidation step because it can happen that the same ocmpany appears in different documents. 

I need your help with the following things:

1. The consolidation step is failing for some companies, probably because there is very little information to retrieve. 
In those cases instead of throwing an error, I prefer to just being directed to the companies page but showing there a simple message like no company data retrieved. 
2. The companies data after consolidation is not being stored correctly I believe in the databases. 
3. I need a better wat to save/store sessions, because it looks weird now, I need one easier way to have a single session for the user and let it change the documents that he is analyzing. 

Here is the file structure of the project

|-- favicon.ico
|-- globals.css
|-- layout.tsx
|-- page.tsx
|-- types.ts
|-- data-aggregated
  |-- page.tsx
|-- companies
  |-- page.tsx
|-- settings
  |-- page.tsx
|-- login
  |-- page.tsx
|-- signup
  |-- page.tsx
|-- dashboard
  |-- page.tsx
  |-- useChat.tsx
  |-- useFileProcessing.tsx
  |-- utils
    |-- fileTreeHelpers.tsx
|-- data
  |-- page.tsx
  |-- [cik]
    |-- page.tsx
|-- history
  |-- page.tsx
  |-- [sessionId]
    |-- page.tsx
|-- api
  |-- company-facts
    |-- route.tsx
  |-- account-data
    |-- route.tsx
  |-- all-accounts
    |-- route.tsx
  |-- financial-data
    |-- route.tsx
  |-- countTokens
    |-- route.tsx
  |-- session-file
    |-- route.tsx
  |-- search
    |-- route.tsx
  |-- llm
    |-- route.tsx
  |-- submission-history
    |-- route.tsx
  |-- store-heavy-data
    |-- route.tsx
  |-- test
    |-- route.tsx
  |-- auth
    |-- login
      |-- route.tsx
    |-- signup
      |-- route.tsx
  |-- files
    |-- route.tsx
    |-- [fileId]
      |-- route.tsx
  |-- sessions
    |-- route.tsx
    |-- [sessionId]
      |-- route.tsx
  |-- uploads
    |-- route.tsx
    |-- [uploadId]
      |-- route.tsx
|-- AlphyAnimation.tsx
|-- AnalysisPreview.tsx
|-- ChatMessage.tsx
|-- CompanyInfoComponent.tsx
|-- CompanySearch.tsx
|-- ExtractedTextComponent.tsx
|-- FileTree.tsx
|-- FileUploader.tsx
|-- Footer.tsx
|-- Navbar.tsx
|-- SummaryContent.tsx
|-- TestimonialsSlider.tsx
|-- dashboard
  |-- ChatSection.tsx
  |-- FileAnalysisProgress.tsx
  |-- FilePreviewSection.tsx
  |-- FileUploadArea.tsx
  |-- LoadSessionModal.tsx
  |-- ModelSelector.tsx
  |-- RadioButtons.tsx
  |-- SaveSessionModal.tsx
  |-- SessionNameModal.tsx
|-- ui
  |-- card.tsx
  |-- command.tsx
  |-- company-facts-page.tsx
  |-- input.tsx
  |-- search-form.tsx
  |-- search-input.tsx
  |-- search-results.tsx
  |-- skeleton.tsx
  |-- spinner.tsx

plus some other standard files in a Next.js project.

Always return the code in a clear manner, commented, and using best practices. If you are not returning the entire code of 
the file you need to be extremely clear where I should incorporate that code. 

Here are the files you need 

File: app/dashboard/page.tsx
----------------------------------------
'use client';

import { useRef, useState, useEffect } from 'react';
import { useRouter } from 'next/navigation';

// Components
import FileTree, { FileNode } from '@/components/FileTree';
import SelectedFilePanel from '@/components/dashboard/FilePreviewSection';
import ChatSection from '@/components/dashboard/ChatSection';
import ChatContextRadioButtons from '@/components/dashboard/RadioButtons';
import ModelSelector from '@/components/dashboard/ModelSelector';
import FileAnalysisButtons from '@/components/dashboard/FileAnalysisProgress';
import SaveModal from '@/components/dashboard/SaveSessionModal';
import LoadModal from '@/components/dashboard/LoadSessionModal';
import FileUploadArea from '@/components/dashboard/FileUploadArea'; // We'll use this now

// Hooks
import { useFileProcessing } from './useFileProcessing';
import { useChat } from './useChat';

// Utility
import { addBase64ToTree, convertTree } from './utils/fileTreeHelpers';

// Icons (optional usage)
import { InformationCircleIcon } from '@heroicons/react/24/outline';

// Types
import { SessionSummary } from '@/app/history/page';
import { run } from 'node:test';
import Navbar from '@/components/Navbar';

// ---------------------------------------------------
// Helper Functions (NEWLY ADDED)
// ---------------------------------------------------

// Token estimation with optional GPT-3 encoder
const estimateTokens = (text: string): number => {
  // Simple heuristic (1 token â‰ˆ 4 characters)
  const heuristicEstimate = Math.ceil(text.length / 4);

  // For better accuracy, you could use a tokenizer library like `gpt-3-encoder`:
  // const { encode } = require('gpt-3-encoder');
  // return encode(text).length;

  return heuristicEstimate;
};

const mergeConsolidatedCompanies = (companiesArray: any[]) => {
  const companyMap = new Map<string, any>();

  companiesArray.flat().forEach((company) => {
    if (!company?.name) return; // Skip invalid entries

    const existing = companyMap.get(company.name);
    const newCompany = deepClone(company);

    // First occurrence
    if (!existing) {
      companyMap.set(company.name, newCompany);
      return;
    }

    // Merge numerical values
    Object.entries(newCompany.variables).forEach(([key, value]) => {
      if (typeof value === 'number') {
        existing.variables[key] = (existing.variables[key] || 0) + value;
      } else if (value instanceof Date) {
        existing.variables[key] = value > existing.variables[key] ? value : existing.variables[key];
      } else {
        existing.variables[key] = value || existing.variables[key];
      }
    });

    // Merge dates
    existing.dates = Array.from(
      new Set([...existing.dates, ...newCompany.dates])
    ).sort((a, b) => new Date(a).getTime() - new Date(b).getTime());

    // Merge other fields
    existing.lastUpdated = [existing.lastUpdated, newCompany.lastUpdated]
      .filter(Boolean)
      .sort()
      .pop();
  });

  return Array.from(companyMap.values());
};

// Deep clone helper
const deepClone = (obj: any) => JSON.parse(JSON.stringify(obj));

// Deep merge helper
const deepMerge = (target: any, source: any) => {
  Object.keys(source).forEach((key) => {
    if (source[key] instanceof Object && key in target) {
      Object.assign(source[key], deepMerge(target[key], source[key]));
    }
  });
  return Object.assign(target, source);
};

// ---------------------------------------------------

type ExistingUpload = {
  upload_id: number;
  upload_name: string;
};

export default function Dashboard() {
  const router = useRouter();
  const formRef = useRef<HTMLFormElement | null>(null);

  // ---------------------------
  // State for File Processing
  // ---------------------------
  const {
    fileTree,
    setFileTree,
    extractedTexts,
    setExtractedTexts,
    summaries,
    setSummaries,
    extractedCompanies,
    rawResponses,
    setRawResponses,
    isAnalyzing,
    processingPhase,
    progress,
    totalFiles,
    processedFiles,
    processZip,
    processFolder,
    analyzeFiles,
    toggleAllFiles,
    saveHeavyData,
    getConsolidationPrompt,
    consolidatedCompanies,
  } = useFileProcessing();

  // ---------------------------
  // State for Chat
  // ---------------------------
  const {
    contextType,
    setContextType,
    chatMessage,
    setChatMessage,
    chatHistory,
    setChatHistory,
    isChatLoading,
    handleChatSubmit,
  } = useChat();

  const [selectedSummarizationModel, setSelectedSummarizationModel] = useState('deepseek:deepseek-chat');
  const [selectedInfoRetrievalModel, setSelectedInfoRetrievalModel] = useState('deepseek:deepseek-reasoner');
  const [runSummarization, setRunSummarization] = useState(true);
  const [runInfoRetrieval, setRunInfoRetrieval] = useState(true);
  const [currentZipName, setCurrentZipName] = useState<string | null>(null);
  const [highlightedFiles, setHighlightedFiles] = useState<Set<string>>(new Set());
  const [showExtracted, setShowExtracted] = useState(false);
  const [allSelected, setAllSelected] = useState(true);
  const [currentSessionId, setCurrentSessionId] = useState<string | null>(null);
  const [selectedFile, setSelectedFile] = useState<FileNode | null>(null);
  const [successMessage, setSuccessMessage] = useState('');
  const [showSaveModal, setShowSaveModal] = useState(false);
  const [existingUploads, setExistingUploads] = useState<ExistingUpload[]>([]);
  const [selectedUploadOption, setSelectedUploadOption] = useState<'new' | 'existing'>('new');
  const [newUploadName, setNewUploadName] = useState('');
  const [existingUploadId, setExistingUploadId] = useState<number | null>(null);
  const [fetchingUploads, setFetchingUploads] = useState(false);
  const [showLoadModal, setShowLoadModal] = useState(false);
  const [availableSessions, setAvailableSessions] = useState<SessionSummary[]>([]);
  const [isConsolidating, setIsConsolidating] = useState(false);

  // New state for LLM consolidation debug info
  const [llmConsolidationDebug, setLlmConsolidationDebug] = useState<
    { prompt: string; response: string }[]
  >([]);

  // New state to toggle showing the debug panel
  const [showDebug, setShowDebug] = useState(false);

  // ---------------------------------------------------
  // Consolidate Companies (UPDATED)
  // ---------------------------------------------------
  const handleConsolidateCompanies = async (sessionId: string) => {
    setIsConsolidating(true);
    try {

      const MAX_TOKENS = 65536;
      const SAFETY_MARGIN = 1000;
      const systemMessage = 'You are a data consolidation assistant. Merge company information, prioritizing newer data and resolving conflicts.';
      
      // Get all extracted companies from all files
      const allCompanies = Object.values(extractedCompanies).flat();
  
      // 2. Create chunks based on actual token counts
      const chunks: any[][] = [];
      let currentChunk: any[] = [];
      let currentTokens = 0;
  
      // Base tokens (system message + prompt template without data)
      const basePrompt = getConsolidationPrompt([]);
      const baseTokens = estimateTokens(systemMessage) + estimateTokens(basePrompt) + SAFETY_MARGIN;
  
      for (const company of allCompanies) {
        const companyText = JSON.stringify(company);
        const entryTokens = estimateTokens(companyText) + 50;
  
        // Validate single company size
        if (entryTokens > MAX_TOKENS - baseTokens) {
          console.error('Oversized company:', company.name);
          continue; // Skip or implement alternative handling
        }
  
        // Start new chunk if needed
        if (currentTokens + entryTokens > MAX_TOKENS - baseTokens) {
          chunks.push(currentChunk);
          currentChunk = [];
          currentTokens = 0;
        }
  
        currentChunk.push(company);
        currentTokens += entryTokens;
      }
  
      // Add remaining companies
      if (currentChunk.length > 0) {
        chunks.push(currentChunk);
      }
  
      // 3. Process chunks with retry logic
      const consolidationDebug: Array<{ prompt: string; response: string }> = [];
      const MAX_RETRIES = 2;
      
      const processChunk = async (chunk: any[], attempt = 0): Promise<any[]> => {
        try {
          const chunkPrompt = getConsolidationPrompt(chunk);
          const res = await fetch('/api/llm', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              prompt: chunkPrompt,
              model: selectedInfoRetrievalModel,
              format: 'json',
              requestType: 'consolidation',
            }),
          });
  
          if (!res.ok) throw new Error(`HTTP ${res.status}`);
          
          const { content } = await res.json();
          const cleanedContent = content.replace(/```json/g, '').replace(/```/g, '').trim();
          
          // Validate JSON structure
          const parsed = JSON.parse(cleanedContent);
          if (!Array.isArray(parsed)) {
            throw new Error('Invalid response format - expected array');
          }
  
          // Validate minimum company fields
          const validCompanies = parsed.filter(c => 
            c?.name && c?.type && c?.variables && typeof c.variables === 'object'
          );
  
          consolidationDebug.push({ 
            prompt: chunkPrompt, 
            response: JSON.stringify(validCompanies) 
          });
  
          return validCompanies;
        } catch (error) {
          if (attempt < MAX_RETRIES) {
            await new Promise(resolve => setTimeout(resolve, 1000 * (attempt + 1)));
            return processChunk(chunk, attempt + 1);
          }
          console.error('Chunk processing failed after retries:', error);
          return [];
        }
      };
  
      // 4. Process chunks sequentially to avoid rate limiting
      let consolidatedResults: any[] = [];
      for (const chunk of chunks) {
        const chunkResults = await processChunk(chunk);
        consolidatedResults = mergeConsolidatedCompanies([
          ...consolidatedResults,
          ...chunkResults
        ]);
      }
  
      // 5. Final validation
      if (consolidatedResults.length === 0) {
        throw new Error('Consolidation produced no valid results');
      }
  
      // 6. Save results
      setLlmConsolidationDebug(consolidationDebug);
      await saveHeavyData(sessionId, {
        fileTree,
        extractedTexts,
        summaries,
        extractedCompanies,
        rawResponses,
        consolidatedCompanies: consolidatedResults,
      });
  
      // 7. Debug logging
      if (process.env.NODE_ENV === 'development') {
        console.log('Consolidation chunks:', chunks);
        console.log('Final merged companies:', consolidatedResults);
        console.log('Token usage:', {
          baseTokens,
          perChunk: chunks.map(chunk => ({
            companies: chunk.length,
            tokens: estimateTokens(JSON.stringify(chunk))
          }))
        });
      }
  
      router.push(`/companies?sessionId=${sessionId}`);
    } catch (error) {
      console.error('Consolidation error:', error);
      alert(`Consolidation failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
    } finally {
      setIsConsolidating(false);
    }
  };

  // ---------------------------
  // On Mount: Check User Auth
  // ---------------------------
  useEffect(() => {
    const userId = typeof window !== 'undefined' ? localStorage.getItem('userId') : null;
    if (!userId) {
      router.push('/login');
    }
  }, [router]);

  // ---------------------------
  // Helper to get all files
  // ---------------------------
  const getAllFiles = (nodes: FileNode[]): FileNode[] => {
    return nodes.flatMap((node) => {
      if (node.type === 'folder' && node.children) {
        return getAllFiles(node.children);
      }
      return node.type === 'file' ? [node] : [];
    });
  };

  // ---------------------------
  // File Selection
  // ---------------------------
  const handleFileSelect = (node: FileNode) => {
    if (node.type === 'folder') return;
    if (!node.content) node.content = ''; // Ensure content is always a string
    setSelectedFile(node);
  };

  // ---------------------------
  // "Save Session" Modal
  // ---------------------------
  const openSaveModal = async () => {
    setNewUploadName('');
    setExistingUploadId(null);
    setSelectedUploadOption('new');
    try {
      setFetchingUploads(true);
      const res = await fetch('/api/uploads', {
        headers: { 'x-user-id': localStorage.getItem('userId') || '' },
      });
      if (!res.ok) throw new Error('Failed to fetch existing uploads');
      const data = await res.json();
      setExistingUploads(data.uploads || []);
    } catch (err) {
      console.error('Error fetching uploads:', err);
      setExistingUploads([]);
    } finally {
      setFetchingUploads(false);
      setShowSaveModal(true);
    }
  };

  const closeSaveModal = () => {
    setShowSaveModal(false);
  };

  const handleSaveConfirm = async () => {
    try {
       // Get the session name from your state (you'll need to ensure this is populated)
      const sessionName = newUploadName.trim() || `Session ${new Date().toLocaleDateString()}`;
      const sessionId = await saveSession(sessionName);
      localStorage.setItem('currentSessionId', sessionId);
      setShowSaveModal(false);
    } catch (error) {
      console.error('Error in handleSaveConfirm:', error);
      alert('Error saving data: ' + (error as Error).message);
    }
  };

  async function saveSession(sessionName: string): Promise<string> {
    const fileTreeWithBase64 = addBase64ToTree(fileTree);

    const res = await fetch('/api/sessions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-user-id': localStorage.getItem('userId') || '',
      },
      body: JSON.stringify({ sessionName }),
    });
    if (!res.ok) throw new Error('Failed to save session');
    const data = await res.json();

    setCurrentSessionId(data.session_id);

    await saveHeavyData(data.session_id, {
        fileTree: fileTreeWithBase64,
        extractedTexts,
        summaries,
        extractedCompanies,
        rawResponses,
      });

    setCurrentSessionId(data.session_id);

    setSuccessMessage('Session saved successfully!');

    return data.session_id;
  }

  // ---------------------------
  // "Load Session" Modal
  // ---------------------------
  const handleLoadClick = async () => {
    try {
      const res = await fetch('/api/sessions', {
        headers: { 'x-user-id': localStorage.getItem('userId') || '' },
      });
      const data = await res.json();
      setAvailableSessions(data.sessions);
      setShowLoadModal(true);
    } catch {
      alert('Error loading sessions');
    }
  };

  const confirmLoadSession = async (sessionId: string) => {
    try {
      const userId = localStorage.getItem('userId');
      if (!userId) {
        router.push('/login');
        return;
      }

      // 1) Confirm the session is available
      const response = await fetch('/api/sessions', {
        headers: { 'x-user-id': userId },
      });
      if (!response.ok) throw new Error('Failed to load session');
      const data = await response.json();
      if (!data.sessions || data.sessions.length === 0) {
        alert('No session data found.');
        return;
      }

      setCurrentSessionId(sessionId);

      // 2) Fetch heavy data
      const heavyRes = await fetch(`/api/store-heavy-data?sessionId=${sessionId}`);
      if (!heavyRes.ok) throw new Error('Failed to load heavy data');
      const heavyData = await heavyRes.json();

      setRawResponses(heavyData.rawResponses || {});

      // 3) Rebuild the fileTree from base64
      const rebuiltTree = convertTree(heavyData.fileTree || [], sessionId);
      setFileTree(rebuiltTree);

      // 4) Restore chat history, extracted texts, summaries
      setChatHistory(heavyData.chatHistory || []);
      setExtractedTexts(heavyData.extractedTexts || {});
      setSummaries(heavyData.summaries || {});
      localStorage.setItem('currentSessionId', sessionId);
      setCurrentSessionId(sessionId);
    } catch (error) {
      console.error('Error loading session:', error);
      alert('Error loading session: ' + (error as Error).message);
    }
  };

  // ---------------------------
  // Rendering
  // ---------------------------
  return (
    <div className="min-h-screen bg-gray-50 relative">
      <Navbar />
      <main className="max-w-7xl mx-auto px-4 py-8">
        {/* Success Message */}
        {successMessage && (
          <div className="mb-4 bg-green-100 border border-green-200 text-green-800 p-3 rounded-md">
            {successMessage}
          </div>
        )}

        {/* File Upload Area */}
        <div className="bg-white rounded-lg shadow-sm p-6 mb-6">
          <FileUploadArea
            processZip={processZip}
            processFolder={processFolder}
            handleLoadClick={handleLoadClick}
            isDragActive={false}
          />
        </div>

        {/* Replace the existing ModelSelector section with this */}
        <div className="space-y-4 mb-6 text-gray-600">
          <div className="bg-white p-4 rounded-lg">
            <label className="flex items-center gap-3 mb-2">
              <input
                type="checkbox"
                checked={runSummarization}
                onChange={(e) => setRunSummarization(e.target.checked)}
                className="h-4 w-4"
              />
              <span className="font-medium">Enable Summarization</span>
            </label>
            <ModelSelector
              selectedModel={selectedSummarizationModel}
              onModelChange={setSelectedSummarizationModel}
              disabled={!runSummarization}
            />
          </div>

          <div className="bg-white p-4 rounded-lg shadow-sm">
            <label className="flex items-center gap-3 mb-2">
              <input
                type="checkbox"
                checked={runInfoRetrieval}
                onChange={(e) => setRunInfoRetrieval(e.target.checked)}
                className="h-4 w-4"
              />
              <span className="font-medium">Enable Information Retrieval</span>
            </label>
            <ModelSelector
              selectedModel={selectedInfoRetrievalModel}
              onModelChange={setSelectedInfoRetrievalModel}
              disabled={!runInfoRetrieval}
            />
          </div>
        </div>

        {/* If we have a file tree, show Analyze + Save Buttons */}
        {fileTree.length > 0 && (
          <div className="bg-white rounded-lg shadow-sm p-6 mb-6">
            <div className="mb-4 flex items-center justify-between">
              <FileAnalysisButtons
                fileTree={fileTree}
                summarizationModel={runSummarization ? selectedSummarizationModel : ''}
                infoRetrievalModel={runInfoRetrieval ? selectedInfoRetrievalModel : ''}
                consolidationModel={runInfoRetrieval ? selectedInfoRetrievalModel : ''}
                runSummarization={runSummarization}
                runInfoRetrieval={runInfoRetrieval}
                analyzeFiles={async () => {
                  try {
                    // Run analysis
                        await analyzeFiles({
                          runSummarization,
                          runInfoRetrieval,
                          summarizationModel: runSummarization ? selectedSummarizationModel : undefined,
                          infoRetrievalModel: runInfoRetrieval ? selectedInfoRetrievalModel : undefined
                        });
                  
                        // Auto-save session with generated name
                        const sessionName = `Analysis ${new Date().toLocaleDateString()}`;
                        const sessionId = await saveSession(sessionName);
                        
                      } catch (error) {
                        console.error('Processing error:', error);
                        alert("Analysis failed: " + (error instanceof Error ? error.message : 'Unknown error'));
                      }
                    }}
                openSaveModal={openSaveModal}
                toggleAllFiles={toggleAllFiles}
                allSelected={allSelected}
                setAllSelected={setAllSelected}
                getAllFiles={getAllFiles}
                isAnalyzing={isAnalyzing}
                progress={progress}
                processingPhase={processingPhase}
                processedFiles={processedFiles}
                totalFiles={totalFiles}
              />
            </div>

            {/* Actual File Tree */}
            <FileTree
              nodes={fileTree}
              onSelect={handleFileSelect}
              selectedFile={
                selectedFile ? { ...selectedFile, content: selectedFile.content || '' } : null
              }
              onToggleConversion={(path) => {
                const updateNodes = (nodes: FileNode[]): FileNode[] =>
                  nodes.map((n) => ({
                    ...n,
                    selected: n.fullPath === path ? !n.selected : n.selected,
                    children: n.children ? updateNodes(n.children) : undefined,
                  }));
                setFileTree((prev) => updateNodes(prev));
              }}
              onToggleHighlight={(path) => {
                const newHighlighted = new Set(highlightedFiles);
                if (newHighlighted.has(path)) {
                  newHighlighted.delete(path);
                } else {
                  newHighlighted.add(path);
                }
                setHighlightedFiles(newHighlighted);

                const updateNodes = (nodes: FileNode[]): FileNode[] =>
                  nodes.map((n) => ({
                    ...n,
                    highlighted: newHighlighted.has(n.fullPath!),
                    children: n.children ? updateNodes(n.children) : undefined,
                  }));
                setFileTree(updateNodes(fileTree));
              }}
            />
          </div>
        )}

        {/* Selected File Preview */}
        {selectedFile && (
          <SelectedFilePanel
            selectedFile={{ ...selectedFile, content: selectedFile.content || '' }}
            extractedTexts={extractedTexts}
            extractedCompanies={extractedCompanies}
            summaries={summaries}
            showExtracted={showExtracted}
            setShowExtracted={setShowExtracted}
            rawResponses={rawResponses}
          />
        )}

        {fileTree.length > 0 && (
          <button
            onClick={() => {
              if (!currentSessionId) {
                alert('Please save the session first');
                return;
              }
              handleConsolidateCompanies(currentSessionId);
            }}
            disabled={isConsolidating || !currentSessionId}
            className={`px-4 py-2 rounded ${
              isConsolidating || !currentSessionId
                ? 'bg-gray-300 text-gray-500 cursor-not-allowed'
                : 'bg-blue-600 text-white hover:bg-blue-700'
            }`}
          >
            {isConsolidating ? 'Consolidating...' : 'Consolidate Companies'}
          </button>
        )}

        {/* Toggle Button for Debug Info */}
        <button
          onClick={() => setShowDebug(!showDebug)}
          className="mb-4 bg-gray-200 text-gray-800 px-3 py-1 rounded ml-2"
        >
          {showDebug ? 'Hide LLM Debug Info' : 'Show LLM Debug Info'}
        </button>

        {showDebug && (
          <div className="bg-white p-4 rounded shadow mb-6 max-h-80 overflow-y-auto text-gray-600">
            <h3 className="text-lg font-semibold mb-2">Extraction Debug Info</h3>
            {Object.entries(rawResponses).map(([filePath, debug]) => (
              <div key={filePath} className="mb-4 border-b pb-2">
                <p className="font-medium text-gray-700">File: {filePath}</p>
                <p className="text-sm text-gray-600">
                  <span className="font-semibold">Prompt:</span> {debug.prompt}
                </p>
                <p className="text-sm text-gray-600">
                  <span className="font-semibold">Response:</span> {debug.response}
                </p>
              </div>
            ))}
            {llmConsolidationDebug.length > 0 && (
              <div className="mt-4 border-t pt-2">
                <h3 className="text-lg font-semibold mb-2">Consolidation Debug Info</h3>
                {llmConsolidationDebug.map((debug, index) => (
                  <div key={index} className="mb-4 border-b pb-2">
                    <p className="text-sm text-gray-600">
                      <span className="font-semibold">Prompt:</span> {debug.prompt}
                    </p>
                    <p className="text-sm text-gray-600">
                      <span className="font-semibold">Response:</span> {debug.response}
                    </p>
                  </div>
                ))}
              </div>
            )}
          </div>
        )}
    

        {/* Save Modal */}
        <SaveModal
          showSaveModal={showSaveModal}
          newUploadName={newUploadName}
          setNewUploadName={setNewUploadName}
          closeSaveModal={closeSaveModal}
          handleSaveConfirm={handleSaveConfirm}
        />
      </main>

      {/* Load Modal (rendered outside main for simplicity) */}
      <LoadModal
        showLoadModal={showLoadModal}
        availableSessions={availableSessions}
        confirmLoadSession={confirmLoadSession}
        setShowLoadModal={setShowLoadModal}
      />
    </div>
  );
}

----------------------------------------

File: app/dashboard/useFileProcessing.tsx
----------------------------------------
'use client';
import { useState } from 'react';
import JSZip from 'jszip';
import { getDocument, GlobalWorkerOptions } from 'pdfjs-dist';
import * as XLSX from 'xlsx';
import { TextItem } from 'pdfjs-dist/types/src/display/api';
import { FileNode } from '@/components/FileTree';
import { CompanyInfo } from '@/app/types';
import { ConsolidatedCompany } from '@/app/types';
import { 
  defaultSummarizationTemplate,
  defaultExtractionTemplate,
  defaultConsolidationTemplate,
  defaultVariableExtraction
} from '@/lib/prompts';

GlobalWorkerOptions.workerSrc = '/pdf.worker.mjs';

const DEVELOPMENT = process.env.NEXT_PUBLIC_LLM_DEV_MODE === 'development';

interface FilePayload {
  path: string;
  base64Data: string;
  blobUrl: string;
}

// Helper to convert ArrayBuffer to base64
function arrayBufferToBase64(buffer: ArrayBuffer): string {
  let binary = '';
  const bytes = new Uint8Array(buffer);
  for (let i = 0; i < bytes.length; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}

// Helper to decode base64 back to ArrayBuffer
function base64ToArrayBuffer(base64: string): ArrayBuffer {
  const binary = atob(base64);
  const len = binary.length;
  const buffer = new ArrayBuffer(len);
  const bytes = new Uint8Array(buffer);
  for (let i = 0; i < len; i++) {
    bytes[i] = binary.charCodeAt(i);
  }
  return buffer;
}

export function useFileProcessing() {
  
  const [rawResponses, setRawResponses] = useState<Record<string, { prompt: string; response: string }>>({});
  const [extractedCompanies, setExtractedCompanies] = useState<Record<string, CompanyInfo[]>>({});
  const [fileTree, setFileTree] = useState<FileNode[]>([]);
  const [extractedTexts, setExtractedTexts] = useState<Record<string, string>>({});
  const [summaries, setSummaries] = useState<Record<string, string>>({});

  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [processingPhase, setProcessingPhase] = useState<'extracting' | 'summarizing' | 'idle' | 'extracting_companies'>('idle');
  const [progress, setProgress] = useState(0);
  const [totalFiles, setTotalFiles] = useState(0);
  const [processedFiles, setProcessedFiles] = useState(0);

  const getConsolidationPrompt = (rawData: Record<string, any>) => {
    const template = typeof window !== 'undefined' 
      ? localStorage.getItem('consolidationTemplate') || defaultConsolidationTemplate 
      : defaultConsolidationTemplate;
    return template.replace('{rawData}', JSON.stringify(rawData));
  };
 

  // ======================
  // Build File Tree
  // ======================
  const buildFileTree = (files: FilePayload[]): FileNode[] => {
    const root: FileNode = { name: '', type: 'folder', children: [] };

    files.forEach(({ path, base64Data, blobUrl }) => {
      const parts = path.split('/');
      let current = root;
      const pathSegments: string[] = [];

      parts.forEach((part, i) => {
        if (!part) return;
        pathSegments.push(part);

        const existing = current.children?.find((n) => n.name === part);
        if (existing) {
          current = existing;
        } else {
          const isFile = i === parts.length - 1;
          const newNode: FileNode = {
            name: part,
            type: isFile ? 'file' : 'folder',
            children: isFile ? undefined : [],
            base64Data: isFile ? base64Data : undefined,
            content: isFile ? blobUrl : undefined,
            fullPath: pathSegments.join('/'),
          };
          if (!current.children) current.children = [];
          current.children.push(newNode);
          current = newNode;

          // Default to selected
          if (isFile) {
            newNode.selected = true;
          }
        }
      });
    });

    return root.children || [];
  };

  // ======================
  // ZIP UPLOAD PROCESSING
  // ======================
  const processZip = async (file: File) => {
    const zip = new JSZip();
    const zipContent = await zip.loadAsync(file);

    const files = await Promise.all(
      Object.values(zipContent.files)
        .filter((entry) => !entry.dir)
        .map(async (entry) => {
          // 1) Get raw arraybuffer
          const data = await entry.async('arraybuffer');
          // 2) Immediately convert to base64
          const base64Data = arrayBufferToBase64(data);
          // 3) For browser preview
          const blobUrl = URL.createObjectURL(new Blob([data]));
          return {
            path: entry.name,
            base64Data,
            blobUrl,
          };
        })
    );

    setFileTree(buildFileTree(files));
  };

  // ======================
  // FOLDER UPLOAD
  // ======================
  const processFolder = async (fileList: FileList) => {
    const filePromises = Array.from(fileList).map((file) => {
      return new Promise<FilePayload>((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = () => {
          if (reader.result && typeof reader.result !== 'string') {
            // Convert arraybuffer to base64
            const base64Data = arrayBufferToBase64(reader.result);
            const blobUrl = URL.createObjectURL(file);
            resolve({
              path: file.webkitRelativePath,
              base64Data,
              blobUrl,
            });
          } else {
            reject(new Error('Failed to read file as ArrayBuffer'));
          }
        };
        reader.onerror = (err) => reject(err);
        reader.readAsArrayBuffer(file);
      });
    });

    try {
      const files = await Promise.all(filePromises);
      setFileTree(buildFileTree(files));
    } catch (err) {
      console.error('Error reading folder files:', err);
    }
  };

  // Helper: get all files in a tree
  const getAllFiles = (nodes: FileNode[]): FileNode[] => {
    return nodes.flatMap((node) => {
      if (node.type === 'folder' && node.children) {
        return getAllFiles(node.children);
      }
      return node.type === 'file' ? [node] : [];
    });
  };

  // ======================
  // ANALYZE FILES
  // ======================
  const analyzeFiles = async (options: {
    runSummarization: boolean
    runInfoRetrieval: boolean
    summarizationModel?: string
    infoRetrievalModel?: string
  }) => {
    try {
      const allFiles = getAllFiles(fileTree).filter((f) => f.selected);
      setProcessingPhase('extracting');
      setIsAnalyzing(true);
      setProgress(0);
      setProcessedFiles(0);

      const total = allFiles.length;
      setTotalFiles(total);

      const newExtractedTexts: Record<string, string> = {};
      let processedCount = 0;

      for (const node of allFiles) {
        let extracted = '';

        if (!node.base64Data) continue;

        const arrayBuffer = base64ToArrayBuffer(node.base64Data);

        if (node.name.toLowerCase().endsWith('.pdf')) {
          try {
            const data = new Uint8Array(arrayBuffer);
            const pdf = await getDocument({ data }).promise;
            let text = '';
            for (let i = 1; i <= pdf.numPages; i++) {
              const page = await pdf.getPage(i);
              const content = await page.getTextContent();
              text += content.items
                .filter((item): item is TextItem => 'str' in item)
                .map((item: TextItem) => item.str)
                .join(' ') + '\n';
            }
            extracted = text;
          } catch (err) {
            console.error(`Failed to extract text from ${node.name}`, err);
            extracted = '[Error extracting PDF text]';
          }
        }else if (node.name.toLowerCase().match(/\.(xlsx|xls)$/)) {
          try {
            const workbook = XLSX.read(new Uint8Array(arrayBuffer), { type: 'array' });
            let excelText = '';
            workbook.SheetNames.forEach((sheetName) => {
              const worksheet = workbook.Sheets[sheetName];
              const sheetAsJson = XLSX.utils.sheet_to_json(worksheet, { header: 1 });
              (sheetAsJson as (string | number | boolean | null)[][]).forEach((row) => {
                excelText += row.join(' ') + '\n';
              });
              excelText += '\n';
            });
            extracted = excelText;
          } catch (err) {
            console.error(`Failed to extract text from ${node.name}`, err);
            extracted = '[Error extracting Excel text]';
          }
        }
        else {
          extracted = '[Text extraction not available for this file type]';
        }

        newExtractedTexts[node.fullPath!] = extracted.trim().replace(/\s+/g, ' ');
        processedCount++;
        setProcessedFiles(processedCount);
        setProgress(Math.round((processedCount / total) * 100));
      }
      setExtractedTexts(newExtractedTexts);

      const textEntries = Object.entries(newExtractedTexts);

      if (options.runSummarization && options.summarizationModel) {

      // Phase 2: Summarization
      setProcessingPhase('summarizing');
      setProgress(0);
      setProcessedFiles(0);

      const newSummaries: Record<string, string> = {};
      let summaryCount = 0;
      

      for (const [fullPath, text] of textEntries) {
        try {
          const template = typeof window !== 'undefined' 
          ? localStorage.getItem('summarizationTemplate') || defaultSummarizationTemplate 
          : defaultSummarizationTemplate;
        const prompt = template.replace('{documentText}', text);

          if (process.env.NEXT_PUBLIC_LLM_DEV_MODE === 'development') {
            newSummaries[fullPath] = 'Some random text for development purposes...';
          } else {
            const res = await fetch('/api/llm', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                prompt,
                history: [],
                model: options.summarizationModel,
                requestType: 'summarize',
              }),
            });

            if (!res.ok) {
              console.error('Summary API error:', res.statusText);
              newSummaries[fullPath] = 'Summary failed: API error';
            } else {
              const data = await res.json();
              let summaryText = data.content;
              summaryText = summaryText.replace(/```json/gi, '').replace(/```/g, '').trim();
              newSummaries[fullPath] = summaryText;
            }
          }
        } catch (error) {
          newSummaries[fullPath] = `Summary failed: ${(error as Error).message}`;
        }

        summaryCount++;
        setProcessedFiles(summaryCount);
        setProgress(Math.round((summaryCount / textEntries.length) * 100));
      }

      setSummaries(newSummaries);
    }

    if (options.runInfoRetrieval && options.infoRetrievalModel) {
      setProcessingPhase('extracting_companies');
      setProgress(0);
      setProcessedFiles(0);

      // We extract first the variables that are present

      let variables  = '';

      for (const [fullPath, text] of textEntries) {
        const template = typeof window !== 'undefined'
          ? localStorage.getItem('variableExtraction') || defaultVariableExtraction
          : defaultVariableExtraction;
        const variables_prompt = template.replace('{text}', text);

        const res = await fetch('/api/llm', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            prompt: variables_prompt,
            model: options.infoRetrievalModel,
            format: 'json',
            requestType: 'extract',
          }),
        });

        if (res.ok) {
          const data = await res.json();
          const cleaned = data.content
            .replace(/```json\s*/i, '')
            .replace(/```/g, '')
            .trim();
          variables += cleaned;
        }
      }

      const newExtractedCompanies: Record<string, CompanyInfo[]> = {};
      let companyCount = 0;
      
      for (const [fullPath, text] of textEntries) {
        try {
          const template = typeof window !== 'undefined' 
          ? localStorage.getItem('extractionTemplate') || defaultExtractionTemplate 
          : defaultExtractionTemplate;
        const extractionPrompt = template
          .replace('{variables}', variables)
          .replace('{documentText}', text);
      
          if (DEVELOPMENT) {
            newExtractedCompanies[fullPath] = [{
              name: 'Example Corp',
              sector: 'Technology',
              profits: { '2022': 1500000, '2023': 2000000 },
              assets: { '2022': 5000000, '2023': 6000000 },
              years: [2022, 2023]
            }];
          } else {
            const res = await fetch('/api/llm', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                prompt: extractionPrompt,
                model: options.infoRetrievalModel,
                format: 'json',
                requestType: 'extract',
              }),
            });
      
            if (res.ok) {
              const data = await res.json();
              const rawResponse = data.content;
              // Store both the prompt and the raw response for debugging
              setRawResponses(prev => ({ ...prev, [fullPath]: { prompt: extractionPrompt, response: rawResponse } }));
      
              const cleaned = rawResponse
                .replace(/```json\s*/i, '')
                .replace(/```/g, '')
                .trim();
      

              try {
                // Expecting an array
                const companies: CompanyInfo[] = JSON.parse(cleaned);
                newExtractedCompanies[fullPath] = companies;
              } catch (e) {
                console.error('Failed to parse company data:', e);
                newExtractedCompanies[fullPath] = [];
              }
            } else {
              newExtractedCompanies[fullPath] = [];
            }
          }
        } catch (error) {
          newExtractedCompanies[fullPath] = [];
        }
      
        companyCount++;
        setProcessedFiles(companyCount);
        setProgress(Math.round((companyCount / textEntries.length) * 100));
      }
      
      setExtractedCompanies(newExtractedCompanies);
    }
      
      } catch (error) {
        console.error('Processing error:', error);
      } finally {
        setIsAnalyzing(false);
        setProcessingPhase('idle');
      }
    };

  // ======================
  // SELECT/DESELECT ALL
  // ======================
  const toggleAllFiles = (selected: boolean) => {
    const updateNodes = (nodes: FileNode[]): FileNode[] =>
      nodes.map((n) => ({
        ...n,
        selected: n.type === 'file' ? selected : n.selected,
        children: n.children ? updateNodes(n.children) : undefined,
      }));
    setFileTree((prev) => updateNodes(prev));
  };

   // Example snippet after analysis completes OR on "Save Session":
   const saveHeavyData = async (
    sessionId: string,
    heavyData: {
      fileTree: FileNode[];
      extractedTexts: Record<string, string>;
      summaries: Record<string, string>;
      extractedCompanies: Record<string, CompanyInfo[]>;
      rawResponses: Record<string, { prompt: string; response: string }>;
      consolidatedCompanies?: ConsolidatedCompany[]; 
    }
  ) => {
    try {
      const res = await fetch('/api/store-heavy-data', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          sessionId,
          heavyData,
        }),
      });
      if (!res.ok) throw new Error('Failed to save heavy data');
     
    } catch (error) {
      console.error(error);
      throw error;
    }
  };

  return {     fileTree, 
    setFileTree, 
    extractedTexts, 
    setExtractedTexts, 
    summaries, 
    setSummaries, 
    isAnalyzing,
    processingPhase, 
    progress, 
    totalFiles, 
    processedFiles, 
    processZip, 
    processFolder, 
    analyzeFiles, 
    toggleAllFiles, 
    getConsolidationPrompt,  // exposed for use in dashboard
    saveHeavyData, 
    extractedCompanies, 
    setExtractedCompanies,
    rawResponses,
    setRawResponses,
    consolidatedCompanies: [] as ConsolidatedCompany[]
  };
}

----------------------------------------

File: app/companies/page.tsx
----------------------------------------
// app/companies/page.tsx
'use client';

import { useEffect, useState } from 'react';
import { useSearchParams } from 'next/navigation';
import Navbar from '@/components/Navbar';

interface VariableData {
  value?: number | string;
  currency?: string;
  unit?: string;
}

interface ConsolidatedCompany {
  name: string;
  type: 'company' | 'fund';
  description: string;
  variables: Record<string, Record<number, VariableData>>;
  dates: string[];
}

export default function CompaniesPage() {
  const searchParams = useSearchParams();
  const sessionId = searchParams.get('sessionId');
  const [companies, setCompanies] = useState<ConsolidatedCompany[]>([]);
  const [loading, setLoading] = useState(true);
  const [selectedYears, setSelectedYears] = useState<Record<string, number>>({});

  useEffect(() => {
    const fetchConsolidatedData = async () => {
      if (!sessionId) return;

      try {
        const response = await fetch(`/api/store-heavy-data?sessionId=${sessionId}`);
        if (!response.ok) throw new Error('Failed to fetch data');
        const data = await response.json();

        if (data.consolidatedCompanies) {
          setCompanies(data.consolidatedCompanies);
        } else {
          setCompanies([]);
        }
      } catch (error) {
        console.error('Error loading companies:', error);
      } finally {
        setLoading(false);
      }
    };

    fetchConsolidatedData();
  }, [sessionId]);

  const getCompanyYears = (company: ConsolidatedCompany): number[] => {
    const years = new Set<number>();
    Object.values(company.variables).forEach(variable => {
      Object.keys(variable).forEach(yearStr => {
        const year = parseInt(yearStr, 10);
        if (!isNaN(year)) years.add(year);
      });
    });
    return Array.from(years).sort((a, b) => b - a);
  };

  if (loading) {
    return (
      <div className="min-h-screen bg-gray-50">
        <div className="max-w-7xl mx-auto px-4 py-8">
          <p>Loading...</p>
        </div>
      </div>
    );
  }

  const renderCompanySection = (type: 'company' | 'fund', color: string) => {
    const filteredCompanies = companies.filter(c => c.type === type);
    if (filteredCompanies.length === 0) return null;

    return (
      <div className="mb-8 text-gray-500">
        <Navbar />
        <h2 className="text-xl font-bold mb-4" style={{ color }}>
          {type === 'fund' ? 'Funds' : 'Companies'}
        </h2>
        {filteredCompanies.map(company => {
          const companyYears = getCompanyYears(company);
          const latestYear = companyYears[0] || null;
          const selectedYear = selectedYears[company.name] ?? latestYear;

          return (
            <div 
              key={company.name}
              className="bg-white p-6 rounded-lg shadow-sm mb-4 border-l-4"
              style={{ borderColor: color }}
            >
              <div className="flex justify-between items-center mb-4">
                <h2 className="text-xl font-semibold">{company.name}</h2>
                {companyYears.length > 0 && (
                  <select
                    value={selectedYear || ''}
                    onChange={(e) => {
                      const year = parseInt(e.target.value, 10);
                      setSelectedYears(prev => ({
                        ...prev,
                        [company.name]: year
                      }));
                    }}
                    className="px-4 py-2 border rounded"
                  >
                    {companyYears.map(year => (
                      <option key={year} value={year}>{year}</option>
                    ))}
                  </select>
                )}
              </div>
              
              {company.description && (
                <p className="text-gray-600 mb-4">{company.description}</p>
              )}

              <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                {Object.entries(company.variables).map(([varName, years]) => {
                  const varData = years[selectedYear];
                  return varData ? (
                    <div 
                      key={varName}
                      className="p-4 rounded"
                      style={{ backgroundColor: `${color}10` }}
                    >
                      <div className="flex justify-between items-center">
                        <span className="font-medium capitalize">
                          {varName.replace(/_/g, ' ')}
                        </span>
                        <span className="text-sm text-gray-600">
                          {varData.currency} {varData.value?.toLocaleString()}
                          {varData.unit}
                        </span>
                      </div>
                    </div>
                  ) : null;
                })}
              </div>
            </div>
          );
        })}
      </div>
    );
  };

  return (
    <div className="min-h-screen bg-gray-50">
      
      <main className="max-w-7xl mx-auto px-4 py-8">
        {renderCompanySection('fund', '#2563eb')}
        {renderCompanySection('company', '#16a34a')}
      </main>
    </div>
  );
}
----------------------------------------

File: app\api\account-data\route.tsx
----------------------------------------
// app/api/account-data/route.ts
import { NextResponse } from "next/server"

const BASE_URL = process.env.NEXT_PUBLIC_EXTERNAL_API_BASE_URL
const API_TOKEN = process.env.NEXT_PUBLIC_EXTERNAL_API_TOKEN

export async function GET(request: Request) {
  try {
    const { searchParams } = new URL(request.url)
    // e.g. "AccountsPayableCurrent"
    const accountParam = searchParams.get("account") ?? ""
    // e.g. "2022" or "2023"
    const yearParam = searchParams.get("year") ?? ""

    if (!accountParam) {
      return NextResponse.json({ error: "Missing 'account' query param" }, { status: 400 })
    }

    // Remote endpoint might be something like:
    //    /all_data_for_account?account=AccountsPayableCurrent&year=2022&api_token=...
    const remoteUrl = `${BASE_URL}/all_data_for_account?account=${accountParam}&year=${yearParam}&api_token=${API_TOKEN}`

    const response = await fetch(remoteUrl)
    if (!response.ok) {
      return NextResponse.json(
        { error: `Upstream error: ${response.statusText}` },
        { status: response.status }
      )
    }

    const data = await response.json()
    return NextResponse.json(data)
  } catch (err) {
    console.error("Error in /api/account-data route:", err)
    return NextResponse.json({ error: "Internal server error" }, { status: 500 })
  }
}

----------------------------------------

File: app\api\all-accounts\route.tsx
----------------------------------------
// app/api/all-accounts/route.ts
import { NextResponse } from "next/server"

const BASE_URL = process.env.NEXT_PUBLIC_EXTERNAL_API_BASE_URL 
const API_TOKEN = process.env.NEXT_PUBLIC_EXTERNAL_API_TOKEN  

export async function GET() {
  try {
    // Build remote URL
    const remoteUrl = `${BASE_URL}/all_accounts?api_token=${API_TOKEN}`
    console.log("Fetching from:", remoteUrl) 
    // Server-to-server fetch => no CORS issue
    const response = await fetch(remoteUrl)
    if (!response.ok) {
      return NextResponse.json(
        { error: `Upstream error: ${response.statusText}` },
        { status: response.status }
      )
    }

    const data = await response.json()
    return NextResponse.json(data)
  } catch (err) {
    console.error("Error in /api/all-accounts route:", err)
    return NextResponse.json({ error: "Internal server error" }, { status: 500 })
  }
}

----------------------------------------

File: app\api\auth\login\route.tsx
----------------------------------------
'use server';
import { NextResponse } from 'next/server';
import pool from '@/utils/db';
import bcrypt from 'bcryptjs';

export async function POST(request: Request) {
  try {
    const body = await request.json();
    const { email, password } = body;
    if (!email || !password) {
      return NextResponse.json({ error: 'Email and password are required' }, { status: 400 });
    }
    const client = await pool.connect();
    const userRes = await client.query('SELECT * FROM users WHERE email = $1', [email]);
    client.release();
    if (userRes.rowCount === 0) {
      return NextResponse.json({ error: 'Invalid credentials' }, { status: 401 });
    }
    const user = userRes.rows[0];
    const passwordMatch = bcrypt.compareSync(password, user.password_hash);
    if (!passwordMatch) {
      return NextResponse.json({ error: 'Invalid credentials' }, { status: 401 });
    }
    // Return user data (do not include the password hash)
    const userData = { user_id: user.user_id, email: user.email };
    return NextResponse.json({ success: true, user: userData }, { status: 200 });
  } catch (error) {
    console.error('Error in login:', error);
    return NextResponse.json({ error: 'Error logging in' }, { status: 500 });
  }
}

----------------------------------------

File: app\api\auth\signup\route.tsx
----------------------------------------
'use server';
import { NextResponse } from 'next/server';
import pool from '@/utils/db';
import bcrypt from 'bcryptjs';

export async function POST(request: Request) {
  try {
    const body = await request.json();
    const { email, password, company, reason } = body;
    if (!email || !password) {
      return NextResponse.json({ error: 'Email and password are required' }, { status: 400 });
    }
    const client = await pool.connect();
    // Check if the user already exists
    const userCheck = await client.query('SELECT * FROM users WHERE email = $1', [email]);
    if (userCheck && userCheck.rowCount !== null && userCheck.rowCount > 0) {
      client.release();
      return NextResponse.json({ error: 'User already exists' }, { status: 400 });
    }
    // Hash the password
    const salt = bcrypt.genSaltSync(10);
    const password_hash = bcrypt.hashSync(password, salt);
    // Insert new user
    const result = await client.query(
      `INSERT INTO users (email, password_hash, company, reason) 
       VALUES ($1, $2, $3, $4) RETURNING user_id, email`,
      [email, password_hash, company, reason]
    );
    client.release();
    return NextResponse.json({ success: true, user: result.rows[0] }, { status: 200 });
  } catch (error) {
    console.error('Error in signup:', error);
    return NextResponse.json({ error: 'Error signing up' }, { status: 500 });
  }
}

----------------------------------------

File: app\api\company-facts\route.tsx
----------------------------------------
// app/api/company-facts/route.ts

import { NextResponse } from "next/server"

// We'll assume you're using .env for the base URL and token.
// If not, you can hardcode them here.
const BASE_URL = process.env.NEXT_PUBLIC_EXTERNAL_API_BASE_URL
const API_TOKEN = process.env.NEXT_PUBLIC_EXTERNAL_API_TOKEN

export async function GET(request: Request) {
  try {
    // 1) Extract query params from the incoming request
    const { searchParams } = new URL(request.url)
    // e.g. "320193"
    const cik = searchParams.get("cik") ?? ""

    // 2) Build the remote URL
    const remoteUrl = `${BASE_URL}/company_facts?cik=${cik}&api_token=${API_TOKEN}`

    console.log("Fetching from:", remoteUrl)

    // 3) Fetch from the external API (server-to-server, no CORS issues here)
    const response = await fetch(remoteUrl, {
      method: "GET",
    })

    if (!response.ok) {
      // e.g. 404, 500, ...
      return NextResponse.json(
        { error: `Upstream error: ${response.statusText}` },
        { status: response.status }
      )
    }

    // 4) Return the JSON response to the client
    const data = await response.json()
    return NextResponse.json(data)
  } catch (err) {
    return NextResponse.json({ error: "Internal server error" }, { status: 500 })
  }
}

----------------------------------------

File: app\api\countTokens\route.tsx
----------------------------------------


----------------------------------------

File: app\api\files\route.tsx
----------------------------------------
import { NextResponse } from 'next/server';
import pool from '@/utils/db';

export async function POST(request: Request) {
  const client = await pool.connect();
  try {
    const userId = request.headers.get('x-user-id');
    if (!userId) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    const formData = await request.formData();
    const files = formData.getAll('files') as File[];
    
    if (!files || files.length === 0) {
      return NextResponse.json({ error: 'No files provided' }, { status: 400 });
    }

    const insertedFiles = [];
    
    for (const file of files) {
      const buffer = Buffer.from(await file.arrayBuffer());
      const result = await client.query(
        `INSERT INTO files 
         (user_id, file_name, file_type, file_data, session_id)
         VALUES ($1, $2, $3, $4, $5)
         RETURNING file_id`,
         [userId, file.name, file.type, buffer, request.headers.get('x-session-id')]
      );
      insertedFiles.push(result.rows[0].file_id);
    }

    return NextResponse.json({ success: true, fileIds: insertedFiles });
  } catch (error) {
    console.error('File upload error:', error);
    return NextResponse.json({ error: 'File upload failed' }, { status: 500 });
  } finally {
    client.release();
  }
}

export async function GET() {
  try {
    const client = await pool.connect();
    const result = await client.query(`SELECT * FROM files;`);
    client.release();

    return NextResponse.json(result.rows);
  } catch (error) {
    console.error(error);
    return NextResponse.json({ error: 'Error fetching files' }, { status: 500 });
  }
}

----------------------------------------

File: app\api\files\[fileId]\route.tsx
----------------------------------------
import { NextResponse } from 'next/server';
import pool from '@/utils/db';


export async function GET(
  request: Request,
  { params }: { params: { fileId: string } }
) {
  const client = await pool.connect();
  try {
    const fileId = parseInt(params.fileId);
    if (isNaN(fileId)) {
      return NextResponse.json({ error: 'Invalid file ID' }, { status: 400 });
    }

    const result = await client.query(
      `SELECT file_name, file_type, file_data 
       FROM files 
       WHERE file_id = $1`,
      [fileId]
    );

    if (result.rowCount === 0) {
      return NextResponse.json({ error: 'File not found' }, { status: 404 });
    }

    const file = result.rows[0];
    return new NextResponse(file.file_data, {
      headers: {
        'Content-Type': file.file_type,
        'Content-Disposition': `attachment; filename="${file.file_name}"`
      }
    });
  } catch (error) {
    console.error('File download error:', error);
    return NextResponse.json({ error: 'File download failed' }, { status: 500 });
  } finally {
    client.release();
  }
}

export async function DELETE(
  request: Request,
  { params }: { params: { fileId: string } }
) {
  let client;
  try {
    client = await pool.connect();
    const fileId = parseInt(params.fileId, 10);
    if (isNaN(fileId)) {
      return NextResponse.json({ error: 'Invalid file ID' }, { status: 400 });
    }

    // Remove any extractions for this file, then remove the file itself
    await client.query('DELETE FROM extractions WHERE file_id = $1', [fileId]);
    await client.query('DELETE FROM files WHERE file_id = $1', [fileId]);

    client.release();
    return NextResponse.json({ success: true }, { status: 200 });
  } catch (error) {
    console.error('Error deleting file:', error);
    if (client) client.release();
    return NextResponse.json({ error: 'Error deleting file' }, { status: 500 });
  }
}

----------------------------------------

File: app\api\financial-data\route.tsx
----------------------------------------
// app/api/financial-data/route.ts
import { NextResponse } from "next/server"
import { Pool } from 'pg';

const pool = new Pool({
    port: 5432,
    host: 'localhost',
    user: 'postgres',
    password: '1234',
    database: 'sec_financial_data',
});

export async function GET(request: Request) {
  try {
    // 1) Parse query params from the URL
    const { searchParams } = new URL(request.url)
    const nameParam = (searchParams.get("name") ?? "").trim().toLowerCase()
    const tickerParam = (searchParams.get("ticker") ?? "").trim().toLowerCase()
    const cikParam = (searchParams.get("cik") ?? "").trim()

    // 2) Prepare placeholders.
    //    For name, we use a LIKE pattern if it's not empty: '%<name>%'
    //    For ticker, we do an exact match but case-insensitive, so we store it in lowercase and compare with LOWER(t.ticker).
    //    For cik, we do an exact match.
    const nameFilter = nameParam ? `%${nameParam}%` : ""
    const tickerFilter = tickerParam // empty if none provided
    const cikFilter = cikParam // empty if none provided

    // 3) Connect to the database
    const client = await pool.connect()

    // 4) Build and run the query
    //    Explanation:
    //    - LEFT JOIN `tickers` so we can gather possible tickers per `companies` row
    //    - Filter with a combination of name, ticker, and/or cik
    //    - If the corresponding parameter is empty, we skip that filter
    //    - Group by c.cik, c.name so we can do array_agg on the tickers
    const sql = `
      SELECT
        c.cik,
        c.name,
        ARRAY_AGG(t.ticker) AS tickers
      FROM companies c
      LEFT JOIN tickers t ON c.cik = t.cik
      WHERE
        ($1 = '' OR LOWER(c.name) LIKE $1)
        AND ($2 = '' OR LOWER(t.ticker) = $2)
        AND ($3 = '' OR c.cik = $3)
      GROUP BY c.cik, c.name
      ORDER BY c.name ASC
      LIMIT 50;
    `

    const result = await client.query(sql, [
      nameFilter,
      tickerFilter,
      cikFilter,
    ])

    client.release()

    // 5) Return JSON response
    return NextResponse.json(result.rows)
  } catch (error) {
    console.error("Error in /api/financial-data:", error)
    return NextResponse.json(
      { error: "Internal server error" },
      { status: 500 }
    )
  }
}

----------------------------------------

File: app\api\llm\route.tsx
----------------------------------------
// app/api/llm/route.ts
import { NextResponse } from 'next/server'
import pool from '@/utils/db';

export const dynamic = 'force-dynamic';

interface DeepSeekError {
  error: {
    message: string;
    type: string;
    code: string;
  };
}

export async function POST(req: Request) {
  const body = await req.json();
  const { prompt, context, history, model, format, requestType } = body || {};

  if (!prompt || typeof prompt !== 'string') {
    return NextResponse.json({ error: "Invalid prompt" }, { status: 300 });
  }

  const DEVELOPMENT = process.env.NEXT_PUBLIC_LLM_DEV_MODE === 'true';
  const userId = req.headers.get('x-user-id');

  if (DEVELOPMENT) {
    await new Promise(res => setTimeout(res, 500));
    return NextResponse.json({
      content: `[MOCK RESPONSE] ${model || 'no-model'} response...`,
      tokensUsed: 42
    });
  }

  try {
    
    if (model?.startsWith('deepseek:')) {
      const deepseekKey = process.env.DEEPSEEK_API_KEY;
      if (!deepseekKey) {
        console.error('DeepSeek API key missing');
        return NextResponse.json(
          { error: 'DeepSeek API key not configured' },
          { status: 500 }
        );
      }

      const modelName = model.replace('deepseek:', '');
      const messages = [
        { role: 'system', content: context || 'You are a helpful assistant.' },
        ...(Array.isArray(history) ? history : []),
        { role: 'user', content: prompt }
      ];

      const requestPayload = {
        model: modelName,
        messages,
        temperature: 0.0,
        max_tokens: 8000,
        stream: false,
        //response_format: format === 'json' ? { type: 'json_object' } : undefined
      };

      const startTime = Date.now();
      const response = await fetch('https://api.deepseek.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${deepseekKey}`
        },
        body: JSON.stringify(requestPayload)
      });

      const responseTime = Date.now() - startTime;
      const responseText = await response.text();
      
      

      if (!response.ok) {
        console.error('DeepSeek API Error Details:', {
          status: response.status,
          headers: Object.fromEntries(response.headers.entries()),
          body: responseText
        });
        return NextResponse.json(
          { error: `DeepSeek API Error: ${response.statusText}`, details: responseText },
          { status: 500 }
        );
      }

      try {
        if (requestType === 'consolidation') {
        console.log('Consolidation Response:', responseText);
        }

        const data = JSON.parse(responseText);

        let content = '';

        if (requestType === 'consolidation') {
          const rawContent = data.choices[0].message.content;
          content = rawContent.replace(/```json\s*/gi, '').replace(/```/g, '').trim();
          
          // Validate basic structure
          if (!content.startsWith('[') || !content.endsWith(']')) {
            console.error('Invalid consolidation structure:', content);
            content = '[]'; // Return empty array as fallback
          }
        }

        if (requestType === 'summarize') {
          // For summaries, use the message content directly
          content = data.choices[0].message.content;
        } else if (requestType === 'consolidation' || requestType === 'extract') {
           // For structured data, clean JSON formatting
          const rawContent = data.choices[0].message.content;
          content = rawContent.replace(/```json\s*/gi, '').replace(/```/g, '').trim();
        } else {
          content = data.choices[0].message.content;
        }

        return NextResponse.json({
          content: content,
          tokensUsed: data.usage?.total_tokens || 0
        });
      } catch (parseError) {
        if (requestType === 'summarize') {
          return NextResponse.json({
            content: responseText, // Return raw text if JSON parse fails
            tokensUsed: 0
          });
        }
        console.error('Response JSON Parse Error:', parseError);
        return NextResponse.json(
          { error: 'Failed to parse API response', response: responseText },
          { status: 500 }
        );
      }
    }

    if (model?.startsWith('openai:')) {
      // commented for now
    }

    return NextResponse.json(
      { error: 'Unsupported model provider' },
      { status: 400 }
    );

  } catch (error) {
    console.error('LLM Processing Error:', error);
    return NextResponse.json(
      { error: 'LLM processing failed', details: error instanceof Error ? error.message : String(error) },
      { status: 500 }
    );
  }
}
----------------------------------------

File: app\api\search\route.tsx
----------------------------------------
// app/api/search/route.ts
import { NextResponse } from 'next/server';
import pool from '../../../utils/db';

export async function GET(request: Request) {
  const { searchParams } = new URL(request.url);
  const query = searchParams.get('query') || '';

  try {
    const client = await pool.connect();
    const searchQuery = `
      SELECT 
        c.cik,
        c.name,
        ARRAY_AGG(t.ticker) as tickers,
        ts_rank(to_tsvector('english', c.name), plainto_tsquery('english', $1)) as rank
      FROM companies c
      LEFT JOIN tickers t ON c.cik = t.cik
      WHERE 
        to_tsvector('english', c.name) @@ plainto_tsquery('english', $1) OR
        t.ticker = $1 OR
        c.cik = $1
      GROUP BY c.cik, c.name
      ORDER BY rank DESC
      LIMIT 10;
    `;

    const result = await client.query(searchQuery, [query]);
    client.release();

    return NextResponse.json(result.rows.map(row => ({
      ...row,
      searchTerm: row.tickers.includes(query.toUpperCase()) ? query.toUpperCase() : row.cik === query ? query : row.name
    })));
  } catch  {
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}
----------------------------------------

File: app\api\session-file\route.tsx
----------------------------------------
import { NextResponse } from 'next/server';
import fs from 'fs';
import path from 'path';
import mime from 'mime'; // install via `npm install mime` if you want to do more robust MIME detection

export async function GET(request: Request) {
  try {
    const { searchParams } = new URL(request.url);
    const sessionId = searchParams.get('sessionId');
    const filePath = searchParams.get('filePath');

    if (!sessionId || !filePath) {
      return NextResponse.json(
        { error: 'Missing sessionId or filePath' },
        { status: 400 }
      );
    }

    // Construct the absolute path on disk
    const absolutePath = path.join(
      process.cwd(),
      'data',
      sessionId,
      decodeURIComponent(filePath) // Add URI decoding
    );

    console.log('Serving file:', absolutePath);

    if (!fs.existsSync(absolutePath)) {
      return NextResponse.json({ error: 'File not found' }, { status: 404 });
    }

    // Read file from disk
    const fileBuffer = fs.readFileSync(absolutePath);

    // Infer MIME type from the filename extension, or fall back to octet-stream
    const mimeType = mime.getType(absolutePath) || 'application/octet-stream';

    const headers = {
      'Content-Type': mimeType,
      'Content-Disposition': `inline; filename="${path.basename(absolutePath)}"`,
    };
    // Add proper PDF content disposition
    if (mimeType === 'application/pdf') {
      headers['Content-Disposition'] = `inline; filename="${path.basename(absolutePath)}"`;
    } else {
      headers['Content-Disposition'] = `attachment; filename="${path.basename(absolutePath)}"`;
    }

    // Return the file bytes in the response
    return new NextResponse(fileBuffer, {
      headers: headers,
    });
  } catch (error) {
    console.error('Error serving file:', error);
    return NextResponse.json({ error: 'File serving error' }, { status: 500 });
  }
}

----------------------------------------

File: app\api\sessions\route.tsx
----------------------------------------
// app/api/sessions/route.tsx
import { NextResponse } from 'next/server';
import pool from '../../../utils/db';
// app/api/sessions/route.tsx
export async function GET(request: Request) {
  const client = await pool.connect();
  try {
    const userId = request.headers.get('x-user-id');
    if (!userId || isNaN(parseInt(userId))) { // Add numeric validation
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }
  

    const result = await client.query(`
      SELECT 
        s.session_id,
        s.session_name,
        s.created_at,
        (SELECT COUNT(*)::int FROM files f WHERE f.session_id = s.session_id) AS file_count
      FROM sessions s
      WHERE s.user_id = $1
      ORDER BY s.created_at DESC
    `, [userId]);


    
    const sessions = result.rows.map((row) => ({
      session_id: row.session_id,
      session_name: row.session_name,
      created_at: row.created_at,
      file_count: row.file_count
    }));

    return NextResponse.json({ sessions });
  } catch (error) {
    console.error('Session load error:', error);
    //alert(error);
    return NextResponse.json({ error: 'Failed to load sessions' }, { status: 500 });
  } finally {
    client.release();
  }
}



export async function POST(request: Request) {
  const client = await pool.connect();
  await client.query('BEGIN');
  try {
    const userId = request.headers.get('x-user-id');
    if (!userId) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    const { sessionName } = await request.json();


    //columns  session_id | user_id | session_name | created_at | expires_at
    const result = await client.query(`
      INSERT INTO sessions (user_id, session_name)
      VALUES ($1, $2)
      RETURNING session_id, created_at
    `, [userId, sessionName]);

   
    const sessionId = result.rows[0].session_id;

    await client.query('COMMIT');
    return NextResponse.json({
      success: true,
      session_id: sessionId,
      created_at: result.rows[0].created_at
    });
  } catch (error) {
    await client.query('ROLLBACK');
    console.error('Session save error:', error);
    return NextResponse.json({ error: 'Failed to save session' }, { status: 500 });
  } finally {
    client.release();
  }
}
----------------------------------------

File: app\api\sessions\[sessionId]\route.tsx
----------------------------------------
// app/api/sessions/[sessionId]/route.tsx
import { NextResponse } from 'next/server';
import pool from '@/utils/db';
import fs from 'fs';
import path from 'path';

export async function GET(
  request: Request,
  { params }: { params: { sessionId: string } }
) {
  const client = await pool.connect();
  try {
    const userId = request.headers.get('x-user-id');
    if (!userId) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }
    const sId = parseInt(params.sessionId, 10);
    if (isNaN(sId)) {
      return NextResponse.json({ error: 'Invalid session ID' }, { status: 400 });
    }

    const res = await client.query(
      `SELECT session_id, session_name, created_at
         FROM sessions
        WHERE session_id = $1 AND user_id = $2`,
      [sId, userId]
    );
    if (res.rowCount === 0) {
      return NextResponse.json({ error: 'Session not found' }, { status: 404 });
    }
    const session = res.rows[0];
    return NextResponse.json({ session });
  } catch (error) {
    console.error('Error fetching session:', error);
    return NextResponse.json({ error: 'Error fetching session' }, { status: 500 });
  } finally {
    client.release();
  }
}

export async function DELETE(
  request: Request,
  { params }: { params: { sessionId: string } }
) {
  const client = await pool.connect();
  await client.query('BEGIN');
  try {
    const userId = request.headers.get('x-user-id');
    if (!userId) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }
    const sId = parseInt(params.sessionId, 10);
    if (isNaN(sId)) {
      return NextResponse.json({ error: 'Invalid session ID' }, { status: 400 });
    }
    // Optionally, remove the session reference from files (set session_id to NULL)
    await client.query(
      `UPDATE files SET session_id = NULL WHERE session_id = $1 AND user_id = $2`,
      [sId, userId]
    );
    const deleteResult = await client.query(
      `DELETE FROM sessions WHERE session_id = $1 AND user_id = $2`,
      [sId, userId]
    );
    if (deleteResult.rowCount === 0) {
      // Nothing to delete or unauthorized
      await client.query('ROLLBACK');
      return NextResponse.json(
        { error: 'Session not found or not authorized' },
        { status: 404 }
      );
    }

    await client.query('COMMIT');

     // 3) Remove the session folder from disk (best-effort)
    // data/<sessionId> is the folder holding heavyData.json + /files
    const sessionPath = path.join(process.cwd(), 'data', String(sId));
    try {
      // Node 14 and below do not support fs.rmSync, so if you need older Node, use rmdirSync.
      fs.rmSync(sessionPath, { recursive: true, force: true });
      console.log(`Deleted directory: ${sessionPath}`);
    } catch (err) {
      // Not critical if folder removal fails â€“ but we log it.
      console.error(`Failed to remove folder ${sessionPath}:`, err);
    }

    return NextResponse.json({ success: true });
  } catch (error) {
    await client.query('ROLLBACK');
    console.error('Error deleting session:', error);
    return NextResponse.json({ error: 'Error deleting session' }, { status: 500 });
  } finally {
    client.release();
  }
}

----------------------------------------

File: app\api\store-heavy-data\route.tsx
----------------------------------------
// app/api/store-heavy-data/route.ts
import { NextResponse } from 'next/server';
import fs from 'fs';
import path from 'path';
import { FileNode } from '@/components/FileTree';

export async function POST(request: Request) {
  try {
    const { sessionId, heavyData } = await request.json();
    if (!sessionId) {
      return NextResponse.json({ error: 'sessionId is required' }, { status: 400 });
    }

    // 1) Create the directory structure: data/sessionId/files
    const dataDir = path.join(process.cwd(), 'data', sessionId.toString());
    const filesDir = path.join(dataDir, 'files');
    if (!fs.existsSync(dataDir)) {
      fs.mkdirSync(dataDir, { recursive: true });
    }
    if (!fs.existsSync(filesDir)) {
      fs.mkdirSync(filesDir);
    }

    // 2) For each file node in fileTree, decode base64 -> raw file
    function storeFilesRecursively(nodes: FileNode[]): FileNode[] {
      return nodes.map((node, idx) => {
        if (node.type === 'folder' && node.children) {
          return { ...node, children: storeFilesRecursively(node.children) };
        }
        if (node.type === 'file' && node.base64Data) {
          // decode base64
          const buffer = Buffer.from(node.base64Data, 'base64');
          // create a unique filename. You can also keep the original name if you prefer
          // but we add idx or a timestamp to avoid collisions:
          const safeName = node.name.replace(/[^\w\d.]+/g, '_');
          const fileName = `file_${Date.now()}_${idx}_${safeName}`;
          const filePath = path.join(filesDir, fileName);

          // 3) Write the file to data/sessionId/files/
          fs.writeFileSync(filePath, buffer);

          // 4) Remove base64Data from the node, and add localPath
          return {
            ...node,
            base64Data: undefined,
            rawData: undefined,
            localPath: `files/${fileName}`
          };
        }
        return node;
      });
    }

    // If there's a fileTree, store each file on disk
    let updatedFileTree: FileNode[] = [];
    if (heavyData.fileTree) {
      updatedFileTree = storeFilesRecursively(heavyData.fileTree);
    }

    // 5) Overwrite heavyData.fileTree with the updated one
    const filePath = path.join(dataDir, 'heavyData.json');
    const existingData = fs.existsSync(filePath) 
                ? JSON.parse(fs.readFileSync(filePath, 'utf-8'))
                : {};

    const finalHeavyData = {
      ...existingData,
      ...heavyData,
      fileTree: updatedFileTree
    };

    
    fs.writeFileSync(filePath, JSON.stringify(finalHeavyData, null, 2));





    return NextResponse.json({ success: true, filePath });
  } catch (error) {

    return NextResponse.json(
      { error: 'Failed to save heavy data' + error },
      { status: 500 }
    );
  }
}

export async function GET(request: Request) {
  const { searchParams } = new URL(request.url);
  const sessionId = searchParams.get('sessionId');

  if (!sessionId) {
    return NextResponse.json({ error: 'sessionId is required' }, { status: 400 });
  }

  try {
    const dataDir = path.join(process.cwd(), 'data', sessionId);
    const filePath = path.join(dataDir, 'heavyData.json');
    if (!fs.existsSync(filePath)) {
      return NextResponse.json({ error: 'No heavyData found' }, { status: 404 });
    }

    const data = fs.readFileSync(filePath, 'utf-8');
    return NextResponse.json(JSON.parse(data));
  } catch (error) {
    console.error('Error reading heavy data:', error);
    return NextResponse.json({ error: 'Heavy data not found' }, { status: 404 });
  }
}

----------------------------------------

File: app\api\submission-history\route.tsx
----------------------------------------
// app/api/submission-history/route.ts

import { NextResponse } from "next/server"

const BASE_URL = process.env.NEXT_PUBLIC_EXTERNAL_API_BASE_URL
const API_TOKEN = process.env.NEXT_PUBLIC_EXTERNAL_API_TOKEN

export async function GET(request: Request) {
  try {
    const { searchParams } = new URL(request.url)
    const cik = searchParams.get("cik") ?? ""

    const remoteUrl = `${BASE_URL}/submission_history?cik=${cik}&api_token=${API_TOKEN}`
    const response = await fetch(remoteUrl, { method: "GET" })
    if (!response.ok) {
      return NextResponse.json(
        { error: `Upstream error: ${response.statusText}` },
        { status: response.status }
      )
    }

    const data = await response.json()
    return NextResponse.json(data)
  } catch (err) {
    console.error("Error in /api/submission-history route:", err)
    return NextResponse.json({ error: "Internal server error" }, { status: 500 })
  }
}

----------------------------------------

File: app\api\test\route.tsx
----------------------------------------
// app/api/test/route.ts
import { NextResponse } from 'next/server';
import pool from '@/utils/db';

export async function GET() {
  try {
    const client = await pool.connect();
    const result = await client.query('SELECT * FROM files ORDER BY file_id;');
    client.release();

    return NextResponse.json(result.rows);
  } catch (error) {
    console.error('Error fetching data', error);
    return NextResponse.json({ error: 'Error fetching data' }, { status: 500 });
  }
}

----------------------------------------

File: app\api\uploads\route.tsx
----------------------------------------
// app/api/uploads/route.ts
import { NextResponse } from 'next/server';
import pool from '@/utils/db';
import { FileNode } from '@/components/FileTree';

export async function GET(request: Request) {
  const userId = request.headers.get('x-user-id');
  if (!userId) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  try {
    const client = await pool.connect();
    // 1) Fetch all uploads for this user:
    const uploadsResult = await client.query(`
      SELECT upload_id, upload_name, created_at
      FROM uploads
      WHERE user_id = $1
      ORDER BY created_at DESC
    `, [userId]);

    const uploads = uploadsResult.rows;
    client.release();
    return NextResponse.json({ uploads });
  } catch (error) {
    console.error('Error fetching uploads:', error);
    return NextResponse.json({ error: 'Error fetching uploads' }, { status: 500 });
  }
}

export async function POST(request: Request) {
  let client;
  try {
    client = await pool.connect();
    const body = await request.json();
    const { uploadName, fileTree, extractedTexts, summaries, chatHistory } = body;

    // 1) Validate user ID from headers
    const userId = request.headers.get('x-user-id');
    if (!userId) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    // 2) Validate required fields
    if (!uploadName) {
      return NextResponse.json({ error: 'uploadName is required' }, { status: 400 });
    }

    // 3) Create a new "upload" row
    const insertUploadRes = await client.query(
      `INSERT INTO uploads (user_id, upload_name)
       VALUES ($1, $2)
       RETURNING upload_id`,
      [userId, uploadName]
    );
    const newUploadId = insertUploadRes.rows[0].upload_id;

    // 4) Gather all files from the fileTree
    const filesToInsert: Array<{
      fullPath: string;
      fileName: string;
      fileDataBase64?: string;
      mimeType: string;
    }> = [];

    function traverseTree(nodes: FileNode[]) {
      for (const node of nodes) {
        if (node.type === 'file') {
          filesToInsert.push({
            fullPath: node.fullPath || '',
            fileName: node.name,
            fileDataBase64: node.base64Data, // base64 string from the frontend
            mimeType: node.mimeType || 'application/octet-stream'
          });
        }
        if (node.children?.length) {
          traverseTree(node.children);
        }
      }
    }
    traverseTree(fileTree || []);

    // 5) Insert each file row + extraction if applicable
    for (const file of filesToInsert) {
      const fileDataBuffer = file.fileDataBase64
        ? Buffer.from(file.fileDataBase64, 'base64')
        : null;

      // Insert a row in "files"
      const insertFileRes = await client.query(
        `INSERT INTO files (upload_id, file_name, file_path, mime_type, file_data, is_extracted)
         VALUES ($1, $2, $3, $4, $5, $6)
         RETURNING file_id`,
        [
          newUploadId,
          file.fileName,
          file.fullPath,
          file.mimeType,
          fileDataBuffer,
          false
        ]
      );

      const fileId = insertFileRes.rows[0].file_id;

      // If there's text or summary, insert into "extractions"
      const extractedText = extractedTexts?.[file.fullPath];
      const summary = summaries?.[file.fullPath];
      if (extractedText || summary) {
        // Mark file as extracted
        await client.query(
          `UPDATE files SET is_extracted = TRUE WHERE file_id = $1`,
          [fileId]
        );

        // Insert into "extractions"
        await client.query(
          `INSERT INTO extractions (file_id, extracted_text, summarized_text)
           VALUES ($1, $2, $3)`,
          [fileId, extractedText || null, summary || null]
        );
      }
    }

    client.release();

    // Return the upload_id and chatHistory (if any)
    return NextResponse.json(
      { upload_id: newUploadId, chatHistory },
      { status: 200 }
    );
  } catch (error) {
    console.error('Error creating new upload:', error);
    if (client) client.release();
    return NextResponse.json(
      { error: 'Error creating new upload' },
      { status: 500 }
    );
  }
}

----------------------------------------

File: app\api\uploads\[uploadId]\route.tsx
----------------------------------------

import { NextResponse } from 'next/server';
import pool from '@/utils/db';
import { FileNode } from '@/components/FileTree';


export async function DELETE(request: Request,{ params }: { params: { uploadId: string } }) {
  let client;
  try {
    client = await pool.connect();
    const uploadId = parseInt(params.uploadId,10);
    if(isNaN(uploadId)) {
      return NextResponse.json({ error:'Invalid upload ID'},{ status:400 });
    }
    //1) Find all files for this upload
    const fileRes = await client.query(
      'SELECT file_id FROM files WHERE upload_id=$1',[uploadId]
    );
    const fileIds = fileRes.rows.map(r=>r.file_id);
    //2) Delete extractions for these files
    if(fileIds.length>0) {
      await client.query(
        'DELETE FROM extractions WHERE file_id=ANY($1)',
        [fileIds]
      );
    }
    //3) Delete files themselves
    await client.query('DELETE FROM files WHERE upload_id=$1',[uploadId]);
    //4) Finally delete the upload
    await client.query('DELETE FROM uploads WHERE upload_id=$1',[uploadId]);
    client.release();
    return NextResponse.json({ success:true },{ status:200 });
  } catch(error) {
    console.error('Error deleting entire upload:',error);
    if(client) client.release();
    return NextResponse.json({ error:'Error deleting upload'},{ status:500 });
  }
}


export async function PATCH(request: Request,{ params }: { params: { uploadId: string } }) {
  let client;
  try {
    client = await pool.connect();
    const uploadId = parseInt(params.uploadId, 10);
    if (isNaN(uploadId)) {
      return NextResponse.json({ error: 'Invalid upload ID' }, { status: 400 });
    }

    const body = await request.json();
    const { fileTree, extractedTexts, summaries } = body;
    const filesToInsert: Array<{
      fullPath: string;
      fileName: string;
      fileDataBase64?: string;
      mimeType: string;
    }> = [];

    function traverseTree(nodes: FileNode[]) {
      for (const node of nodes) {
        if (node.type === 'file') {
          filesToInsert.push({
            fullPath: node.fullPath || '',
            fileName: node.name,
            fileDataBase64: node.base64Data, // from front end
            mimeType: node.mimeType || 'application/octet-stream'
          });
        }
        if (node.children?.length) traverseTree(node.children);
      }
    }
    traverseTree(fileTree);

    // For each file, either insert or update
    for (const file of filesToInsert) {
      const existingFileRes = await client.query(
        `SELECT file_id FROM files WHERE upload_id = $1 AND file_path = $2`,
        [uploadId, file.fullPath]
      );
      let fileId: number;
      if (existingFileRes.rowCount && existingFileRes.rowCount > 0) {
        fileId = existingFileRes.rows[0].file_id;
        // Potentially update file_data if new base64 data is provided
        if (file.fileDataBase64) {
          const fileDataBuffer = Buffer.from(file.fileDataBase64, 'base64');
          await client.query(
            `UPDATE files
                SET file_data = $2, mime_type=$3
              WHERE file_id = $1`,
            [fileId, fileDataBuffer, file.mimeType]
          );
        }
      } else {
        // Insert new file row
        const fileDataBuffer = file.fileDataBase64
          ? Buffer.from(file.fileDataBase64, 'base64')
          : null;
        const insertRes = await client.query(
          `INSERT INTO files (upload_id, file_name, file_path, mime_type, file_data, is_extracted)
           VALUES ($1, $2, $3, $4, $5, $6)
           RETURNING file_id`,
          [
            uploadId,
            file.fileName,
            file.fullPath,
            file.mimeType,
            fileDataBuffer,
            false
          ]
        );
        fileId = insertRes.rows[0].file_id;
      }

      // Check if we have extraction for that path
      const extractedText = extractedTexts[file.fullPath];
      const summary = summaries[file.fullPath];
      if (extractedText || summary) {
        // Mark file as extracted
        await client.query(`UPDATE files SET is_extracted = TRUE WHERE file_id = $1`, [fileId]);
        // Upsert extraction
        const existingExtractRes = await client.query(
          `SELECT extraction_id FROM extractions WHERE file_id=$1`,
          [fileId]
        );
        if (existingExtractRes.rowCount && existingExtractRes.rowCount > 0) {
          await client.query(
            `UPDATE extractions
                SET extracted_text=$2,
                    summarized_text=$3,
                    updated_at=NOW()
              WHERE file_id=$1`,
            [fileId, extractedText || null, summary || null]
          );
        } else {
          await client.query(
            `INSERT INTO extractions (file_id, extracted_text, summarized_text)
             VALUES ($1,$2,$3)`,
            [fileId, extractedText || null, summary || null]
          );
        }
      }
    }

    client.release();
    return NextResponse.json({ success: true, message: 'Upload updated.' });
  } catch (error) {
    console.error('Error updating upload:', error);
    if (client) client.release();
    return NextResponse.json({ error: 'Error updating upload' }, { status: 500 });
  }
}

----------------------------------------

File: components/CompanyInfoComponent.tsx
----------------------------------------
'use client';
import { CompanyInfo } from '@/app/types';
import React, { useEffect, useState } from 'react';

// Type guard for company data validation
function isCompanyArray(data: any): data is CompanyInfo[] {
  return Array.isArray(data) && data.every(item => 
    typeof item.name === 'string' &&
    (typeof item.sector === 'string' || item.sector === undefined) &&
    (typeof item.years === 'undefined' || Array.isArray(item.years)) &&
    (typeof item.profits === 'undefined' || typeof item.profits === 'object') &&
    (typeof item.assets === 'undefined' || typeof item.assets === 'object')
  );
}

export const CompanyInfoComponent = ({ companies }: { companies: any }) => {
  const [error, setError] = useState<string | null>(null);
  const [validatedCompanies, setValidatedCompanies] = useState<CompanyInfo[]>([]);

  useEffect(() => {
    if (!companies) {
      setError('No company data provided');
      setValidatedCompanies([]);
      return;
    }

    if (!isCompanyArray(companies)) {
      setError('Invalid company data format');
      setValidatedCompanies([]);
      return;
    }

    setError(null);
    setValidatedCompanies(companies);
  }, [companies]);

  if (error) {
    return (
      <div className="mt-4 p-4 bg-red-50 border border-red-200 rounded-md">
        <h3 className="text-red-600 font-medium">Data Error</h3>
        <p className="text-red-500 text-sm">{error}</p>
      </div>
    );
  }

  if (validatedCompanies.length === 0) return null;

  return (
    <div className="mt-8 border-t pt-6">
      <h4 className="text-lg font-semibold text-gray-900 mb-4 flex items-center">
        <span className="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm mr-2">
          Company Data
        </span>
        Extracted Information
      </h4>
      <div className="bg-white rounded-lg border border-gray-200 overflow-hidden text-gray-800">
        {validatedCompanies.map((company, index) => (
          <div key={index} className="p-4 border-b last:border-b-0">
            <div className="grid grid-cols-2 gap-4">
              <div>
                <h3 className="font-medium text-gray-900">{company.name}</h3>
                {company.sector && <p className="text-sm text-gray-600">{company.sector}</p>}
              </div>
              {company.years && company.years.length > 0 && (
                <div className="col-span-2">
                  <div className="grid grid-cols-4 gap-4 text-sm">
                    <div className="font-medium">Year</div>
                    <div className="font-medium">Profits</div>
                    <div className="font-medium">Assets</div>
                    <div className="font-medium"> EBITDA </div>
                    {company.years.map((year, yearIndex) => (
                      <React.Fragment key={yearIndex}>
                        <div className="text-gray-600">{year}</div>
                        <div className="text-gray-600">
                          {company.profits?.[year] || 'N/A'}
                        </div>
                        <div className="text-gray-600">
                          {company.assets?.[year] || 'N/A'}
                        </div>
                        <div className="text-gray-600">
                          {company.ebitda?.[year] || 'N/A'}
                        </div>
                      </React.Fragment>
                    ))}
                  </div>
                </div>
              )}
            </div>
          </div>
        ))}
      </div>
    </div>
  );
};
----------------------------------------


